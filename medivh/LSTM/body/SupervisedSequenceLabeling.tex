\chapter{有监督的序列标注}
本章主要介绍关于有监督序列标注的基本背景知识以及回顾相关文献。\ref{section:Supervised Learning}小节简单的回顾有监督学习，\ref{section:Pattern Classification}小节介绍有监督模式分类的经典、非序列框架，\ref{section:Sequence Labelling}小节提出有监督序列标注的定义，并介绍基于对标签序列的不同假设下的各种序列标注任务。
\section{有监督学习\label{section:Supervised Learning}}
在机器学习中，使用<输入$\rightarrow$输出>作为训练集的任务称为有监督学习。这与增强学习不同，在增强学习中，仅仅只能在训练过程中量化激励值。而在非监督学习中，将不会存在响应数据，算法只能通过不断的试探，寻求数据的结构。本书中，我们不会讨论增强学习和非监督学习。

有监督学习包含了一个训练集$S$，集合的元素是<输入$\rightarrow$输出>对，记为$(x, z)$，其中，$x$是输入空间$\mathcal{X}$中的一个元素，$z$是目标空间$\mathcal{Z}$中的一个元素，伴随训练集一同出现的是测试集$S'$，我们有时候也会将训练集称为训练样本。一般的，我们假定$S$和$S'$都是从相同的输入-输出分布$D_{\mathcal{X}\times \mathcal{Z}}$中独立地抽取出来。在一些案例中，我们会从训练集中选取一部分样本组合成验证集，用于训练过程中验证算法的性能，特别的，为了防止过拟合，往往会把验证集用于确定训练停止的时间。整个过程的目标是，使用测试集训练模型，最小化定义在测试集上的某个误差度量$E$（这个误差度量往往会结合具体任务给出定义），例如，在回归问题中，经常使用的误差度量是平方和，或者输出值与实际值的欧几里得距离的平方。对于参数化方法（比如神经网络），最小化误差的最常用方法是逐步调整参数，使其最优化定义在训练集上的一个损失函数，尽可能地逼近$E$。将训练集上学习到的模型应用到测试集的过程称之为泛化，我们会在本章稍后一点的地方讨论它。

对于不同的监督学习任务，监督者需要提供的基本特征以及监督力度有着很大的不同，例如，训练一个模型让它预测出图片中飞机的每一个像素点的取值要比让它学会识别图中是否存在一辆飞机更困难，前者需要提供更多的信息。为了区分这两种极端情况，	人们有时会将这两种任务所需的数据称为强标签数据以及弱标签数据。
\section{模式分类\label{section:Pattern Classification}}
模式分类，也称为模式识别，是机器学习中的一个广泛的研究领域，一些特定的分类器，比如多层感知器、支持向量机等，现在已在科研圈子广为人知。

尽管模式分类处理的是非序列数据，但底层的实践和理论的框架涵盖了序列数据的情况，因此在讨论序列标注之前，花一点时间简短的回顾它还是有意义的。

有监督模式分类的输入空间$\mathcal{X}$一般记为$\mathbf{R}^M$，也就是说，集合中的每个样本是一个固定长度$M$的实数向量。目标空间$Z$是一个包含了$K$个类别的离散空间。一个模式分类器$h:\mathcal{X}\rightarrow Z$就是一个将向量映射到标签的函数。如果说所有的误分类情况都是坏情况，那么$h$最常用的误差度量是测试集$S'$上的误分率$E^{class}(h, S')$
\begin{equation}
E^{class}(h, S') = \frac{1}{|S'|}\sum\limits_{(x,z)\in S'}\left\{
\begin{array}{ll}
0 & \mbox{若}h(x)=z \\
1 & \mbox{其他} \\
\end{array}\right.
\end{equation}
\subsection{概率分类}
分类器直接输出的是标签，正如支持向量机那样，我们也称这种分类器为判别式函数。另一种方法是概率分类器，它在给定输入模式$x$时返回属于$K$个类别中的$k$的概率$p(C_k|x)$，然后选取最可能的类别作为分类器的输出$h(x)$：
\begin{equation}
h(x) = \arg\max\limits{x}p(C_k|x)
\end{equation}

\subsection{训练概率分类器}
\subsection{生成式模型和判别式模型}
\section{序列标注\label{section:Sequence Labelling}}
\subsection{序列标注任务的一种解决方法}
\subsection{序列分类}
\subsection{段分类}
\subsection{时序分类}
